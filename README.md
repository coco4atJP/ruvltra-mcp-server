# RuvLTRA MCP Server

[English](#english-current-version) | [Êó•Êú¨Ë™û (Japanese)](#Êó•Êú¨Ë™û-japanese)

`ruv/ruvltra-claude-code` „Çí Claude Code / Gemini CLI / Codex „Å™„Å©„ÅÆÊåáÁ§∫Â°î„Ç®„Éº„Ç∏„Çß„É≥„Éà„Åã„Çâ MCP ÁµåÁî±„Åß‰∏¶ÂàóÊ¥ªÁî®„Åô„Çã„Åü„ÇÅ„ÅÆ„Çµ„Éº„Éê„Éº„Åß„Åô„ÄÇ  
ÁèæË°åÂÆüË£Ö„ÅØ„Äå‰∏¶ÂàóÁîüÊàê„Äç„Å†„Åë„Åß„Å™„Åè„ÄÅÈÅãÁî®Âêë„Åë„ÅÆËÄêÈöúÂÆ≥ÊÄßÔºàtimeout, backpressure, retry, circuit breaker, SONAÊ∞∏Á∂öÂåñÔºâ„Åæ„ÅßÂê´„ÇÅ„Å¶„ÅÑ„Åæ„Åô„ÄÇ

---

## Êó•Êú¨Ë™û (Japanese)

RuvLTRA MCP Server „ÅØ„ÄÅÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´ (LLM) „Çí MCP (Model Context Protocol) ÁµåÁî±„Åß‰∏¶ÂàóÂÆüË°å„Åó„ÄÅÂ†ÖÁâ¢„Å™ÁîüÊàê„Éë„Ç§„Éó„É©„Ç§„É≥„ÇíÊèê‰æõ„Åô„Çã„Çµ„Éº„Éê„Éº„Åß„Åô„ÄÇ

### ‰∏ª„Å™Ê©üËÉΩ

- **13Á®ÆÈ°û„ÅÆ MCP „ÉÑ„Éº„É´**: `code_*` (ÁîüÊàê„ÄÅ„É¨„Éì„É•„Éº„ÄÅ„É™„Éï„Ç°„ÇØ„Çø„ÄÅÁøªË®≥„Å™„Å©), `parallel_generate`, `swarm_review` „Å™„Å©
- **WorkerPool „ÅÆÂãïÁöÑ„Çπ„Ç±„Éº„É™„É≥„Ç∞**: Ë≤†Ëç∑„Å´Âøú„Åò„Åü„ÉØ„Éº„Ç´„Éº„ÅÆËá™ÂãïÂ¢óÊ∏õ (2„Äú8) „Å®„Éê„ÉÉ„ÇØ„Éó„É¨„ÉÉ„Ç∑„É£„ÉºÂà∂Âæ°
- **ËÄêÈöúÂÆ≥ÊÄß (Resilience)**: „Çø„Çπ„ÇØ„Åî„Å®„ÅÆ„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÄÅÂÜçË©¶Ë°å (Retry)„ÄÅ„Çµ„Éº„Ç≠„ÉÉ„Éà„Éñ„É¨„Éº„Ç´„Éº„Å´„Çà„ÇãÂÆâÂÆöÁ®ºÂÉç
- **4ÊÆµÈöé„ÅÆÊé®Ë´ñ„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ**: HTTP ‚Üí llama.cpp ‚Üí RuvLLM ‚Üí Mock „ÅÆÈ†Ü„ÅßËá™ÂãïÂàá„ÇäÊõø„Åà
- **SONA Ê∞∏Á∂öÂåñ**: „ÉØ„Éº„Ç´„Éº„Åî„Å®„ÅÆËá™Â∑±ÊîπÂñÑ„Éë„Çø„Éº„É≥„ÅÆ‰øùÂ≠ò„Å®ÂÜç„É≠„Éº„Éâ
- **MCP `outputSchema` + `structuredContent`**: ÂÆâÂÆö„Åó„ÅüÊ©üÊ¢∞Ëß£Êûê„ÅÆ„Åü„ÇÅ„ÅÆÊßãÈÄ†ÂåñÂá∫Âäõ

### „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Ê¶ÇË¶Å

```
  Claude Code / Gemini CLI / Codex (ÊåáÁ§∫Â°î)
                   |
             stdio JSON-RPC
                   v
  +-------------------------------------------+
  | MCP Server Core (13„ÉÑ„Éº„É´)                |
  |  - ‰∏¶ÂàóÁîüÊàê / „Çπ„Ç¶„Ç©„Éº„É†„Éª„É¨„Éì„É•„Éº        |
  |                                           |
  | Worker Pool (ÂãïÁöÑ„Çπ„Ç±„Éº„É´ 2..8)           |
  |  - „Ç≠„É•„ÉºÁÆ°ÁêÜ / „Çø„Ç§„É†„Ç¢„Ç¶„ÉàÂà∂Âæ°          |
  |                                           |
  | Êé®Ë´ñ„Ç®„É≥„Ç∏„É≥ („Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÂà∂Âæ°)         |
  |  HTTP ‚Üí llama.cpp ‚Üí RuvLLM ‚Üí Mock         |
  +-------------------------------------------+
```

### „ÇØ„Ç§„ÉÉ„ÇØ„Çπ„Çø„Éº„Éà

#### npx „ÅßÂç≥Â∫ß„Å´Âà©Áî®„Åô„Çã (Êé®Â•®)

```bash
npx -y ruvltra-mcp-server
```

#### „ÇΩ„Éº„Çπ„Åã„Çâ„Éì„É´„Éâ„Åô„Çã

```bash
npm install
npm run build
node dist/index.js
```

**Áâπ„Å´Áí∞Â¢ÉÂ§âÊï∞„ÇíË®≠ÂÆö„Åó„Å™„Åè„Å¶„ÇÇ„ÄÅRuvLLM „Éê„ÉÉ„ÇØ„Ç®„É≥„Éâ„ÅåËá™Âãï„ÅßÊúâÂäπ„Å´„Å™„Çä„Åæ„Åô„ÄÇ**
ÂàùÂõûËµ∑ÂãïÊôÇ„Å´ `ruvltra-claude-code` „É¢„Éá„É´„ÅåËá™Âãï„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åï„Çå„ÄÅ`~/.ruvllm/models/` „Å´‰øùÂ≠ò„Åï„Çå„Åæ„ÅôÔºànpx „Ç≠„É£„ÉÉ„Ç∑„É•„Å®„ÅØÁã¨Á´ã„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅÂÜç„Ç§„É≥„Çπ„Éà„Éº„É´„Åó„Å¶„ÇÇ„É¢„Éá„É´„ÅØ‰øùÊåÅ„Åï„Çå„Åæ„ÅôÔºâ„ÄÇ

‰ªñ„ÅÆÊé®Ë´ñ„Éê„ÉÉ„ÇØ„Ç®„É≥„Éâ„Çí‰ΩøÁî®„Åó„Åü„ÅÑÂ†¥Âêà„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆÁí∞Â¢ÉÂ§âÊï∞„ÇíË®≠ÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

| ÊñπÂºè | Áí∞Â¢ÉÂ§âÊï∞ | Ë™¨Êòé |
|---|---|---|
| **RuvLLM („Éá„Éï„Ç©„É´„Éà)** | ‰∏çË¶ÅÔºàËá™ÂãïÔºâ | ÂàùÂõûËµ∑ÂãïÊôÇ„Å´„É¢„Éá„É´„ÇíËá™Âãï„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ |
| HTTP | `RUVLTRA_HTTP_ENDPOINT` | OpenAI ‰∫íÊèõ / llama.cpp HTTP „Ç®„É≥„Éâ„Éù„Ç§„É≥„Éà |
| „É≠„Éº„Ç´„É´„É¢„Éá„É´ | `RUVLTRA_MODEL_PATH` | GGUF „É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅÆ„Éë„Çπ (`node-llama-cpp`) |

### „É¢„Éá„É´„ÅÆËá™Âãï„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ

RuvLLM „Éê„ÉÉ„ÇØ„Ç®„É≥„Éâ‰ΩøÁî®ÊôÇ„ÄÅ„É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅØÂàùÂõûËµ∑ÂãïÊôÇ„Å´Ëá™Âãï„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åï„Çå„Åæ„Åô„ÄÇ

| È†ÖÁõÆ | ÂÄ§ |
|---|---|
| „Éá„Éï„Ç©„É´„Éà„É¢„Éá„É´ | `ruvltra-claude-code` (ruv/ruvltra-claude-code) |
| ‰øùÂ≠òÂÖà | `~/.ruvllm/models/` („Éõ„Éº„É†„Éá„Ç£„É¨„ÇØ„Éà„É™Áõ¥‰∏ã) |
| Â§âÊõ¥ÊñπÊ≥ï | Áí∞Â¢ÉÂ§âÊï∞ `RUVLTRA_RUVLLM_MODEL` „ÅßÊåáÂÆö |

> **üí° npx „ÅßËµ∑Âãï„Åó„Å¶„ÇÇ„ÄÅ„É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅØ npx „Ç≠„É£„ÉÉ„Ç∑„É•„Å®„ÅØÂà•„ÅÆÂ†¥ÊâÄ (`~/.ruvllm/models/`) „Å´‰øùÂ≠ò„Åï„Çå„Çã„Åü„ÇÅ„ÄÅÂÜç„Ç§„É≥„Çπ„Éà„Éº„É´„ÇÑ„Ç≠„É£„ÉÉ„Ç∑„É•„ÇØ„É™„Ç¢„Åß„É¢„Éá„É´„ÅåÊ∂à„Åà„Çã„Åì„Å®„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ**

### MCP „ÉÑ„Éº„É´‰∏ÄË¶ß (13Á®Æ)

#### „Ç≥„Éº„ÉâÊìç‰Ωú„ÉÑ„Éº„É´

| „ÉÑ„Éº„É´Âêç | Ë™¨Êòé |
|---|---|
| `ruvltra_code_generate` | ÊåáÁ§∫„Å®„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà„Åã„Çâ„Ç≥„Éº„Éâ„ÇíÁîüÊàê |
| `ruvltra_code_review` | „Ç≥„Éº„Éâ„ÅÆ„Éê„Ç∞„Éª„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Éª„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„Çí„É¨„Éì„É•„Éº |
| `ruvltra_code_refactor` | Âãï‰Ωú„Çí‰øùÊåÅ„Åó„Å§„Å§„Ç≥„Éº„Éâ„Çí„É™„Éï„Ç°„ÇØ„Çø„É™„É≥„Ç∞ |
| `ruvltra_code_explain` | „Ç≥„Éº„Éâ„ÅÆË™¨Êòé„ÇíÁîüÊàê |
| `ruvltra_code_test` | „Ç≥„Éº„Éâ„Å´ÂØæ„Åô„Çã„ÉÜ„Çπ„Éà„ÇíÁîüÊàê |
| `ruvltra_code_fix` | „Ç®„É©„ÉºÊÉÖÂ†±„Åã„Çâ„Ç≥„Éº„Éâ„Çí‰øÆÊ≠£ |
| `ruvltra_code_complete` | „Éó„É¨„Éï„Ç£„ÉÉ„ÇØ„Çπ/„Çµ„Éï„Ç£„ÉÉ„ÇØ„Çπ„Åã„Çâ„Ç≥„Éº„Éâ„ÇíË£úÂÆå |
| `ruvltra_code_translate` | „Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞Ë®ÄË™ûÈñì„Åß„Ç≥„Éº„Éâ„ÇíÁøªË®≥ |

#### ‰∏¶Âàó„Éª„Çπ„Ç¶„Ç©„Éº„É†„ÉÑ„Éº„É´

| „ÉÑ„Éº„É´Âêç | Ë™¨Êòé |
|---|---|
| `ruvltra_parallel_generate` | „ÉØ„Éº„Ç´„Éº„Éó„Éº„É´ÁµåÁî±„ÅßË§áÊï∞„Éï„Ç°„Ç§„É´„Çí‰∏¶ÂàóÁîüÊàê |
| `ruvltra_swarm_review` | ÊúÄÂ§ß8„Å§„ÅÆË¶ñÁÇπ„Åã„Çâ‰∏¶Âàó„Ç≥„Éº„Éâ„É¨„Éì„É•„Éº„ÇíÂÆüË°å |

#### ÁÆ°ÁêÜ„ÉÑ„Éº„É´

| „ÉÑ„Éº„É´Âêç | Ë™¨Êòé |
|---|---|
| `ruvltra_status` | „Çµ„Éº„Éê„Éº„Éª„ÉØ„Éº„Ç´„Éº„Éª„Éê„ÉÉ„ÇØ„Ç®„É≥„Éâ„ÅÆÁä∂ÊÖã„ÇíÂèñÂæó |
| `ruvltra_sona_stats` | SONA Â≠¶ÁøíÁµ±Ë®à„ÇíÂèñÂæó |
| `ruvltra_scale_workers` | „ÉØ„Éº„Ç´„Éº„Éó„Éº„É´„ÅÆ„Çµ„Ç§„Ç∫„ÇíÂãïÁöÑ„Å´Â§âÊõ¥ |

„Åô„Åπ„Å¶„ÅÆ„ÉÑ„Éº„É´„ÅØ `outputSchema` „ÇíÂÆöÁæ©„Åó„ÄÅ`structuredContent` „ÅßÊßãÈÄ†Âåñ„Åï„Çå„ÅüÂøúÁ≠î„ÇíËøî„Åó„Åæ„Åô„ÄÇ

### MCP „ÇØ„É©„Ç§„Ç¢„É≥„ÉàË®≠ÂÆö‰æã

#### Claude Desktop / Claude Code

`~/.claude/claude_desktop_config.json`

```json
{
  "mcpServers": {
    "ruvltra": {
      "command": "npx",
      "args": ["-y", "ruvltra-mcp-server"],
      "env": {
        "RUVLTRA_MIN_WORKERS": "2",
        "RUVLTRA_MAX_WORKERS": "4"
      }
    }
  }
}
```

#### VS Code / Cursor (Antigravity Á≠â)

`mcp_config.json`

```json
{
  "mcpServers": {
    "ruvltra-mcp-server": {
      "command": "npx",
      "args": ["-y", "ruvltra-mcp-server"]
    }
  }
}
```

### „ÉÜ„Çπ„Éà

```bash
# ÂÖ®„ÉÜ„Çπ„Éà„Çπ„Ç§„Éº„ÉàÂÆüË°å
npm test

# ÂÄãÂà•„ÉÜ„Çπ„Éà
npm run test:smoke       # MCP „Çπ„É¢„Éº„ÇØ„ÉÜ„Çπ„Éà
npm run test:pool        # „Çø„Ç§„É†„Ç¢„Ç¶„Éà„Éª„Éê„ÉÉ„ÇØ„Éó„É¨„ÉÉ„Ç∑„É£„Éº
npm run test:resilience  # HTTP „É™„Éà„É©„Ç§„Éª„Çµ„Éº„Ç≠„ÉÉ„Éà„Éñ„É¨„Éº„Ç´„Éº
npm run test:sona        # SONA Ê∞∏Á∂öÂåñ
npm run test:parallel    # ‰∏¶ÂàóÁîüÊàê
```

### Áí∞Â¢ÉÂ§âÊï∞‰∏ÄË¶ß

| Â§âÊï∞Âêç | „Éá„Éï„Ç©„É´„Éà | Ë™¨Êòé |
|---|---:|---|
| `RUVLTRA_MIN_WORKERS` | `2` | ÊúÄÂ∞è„ÉØ„Éº„Ç´„ÉºÊï∞ |
| `RUVLTRA_MAX_WORKERS` | `8` | ÊúÄÂ§ß„ÉØ„Éº„Ç´„ÉºÊï∞ |
| `RUVLTRA_INITIAL_WORKERS` | `2` | ÂàùÊúü„ÉØ„Éº„Ç´„ÉºÊï∞ |
| `RUVLTRA_QUEUE_MAX_LENGTH` | `256` | „Ç≠„É•„ÉºÊúÄÂ§ßÈï∑ |
| `RUVLTRA_TASK_TIMEOUT_MS` | `60000` | „Çø„Çπ„ÇØ„Çø„Ç§„É†„Ç¢„Ç¶„Éà (ms) |
| `RUVLTRA_SONA_ENABLED` | `true` | SONA ÊúâÂäπÂåñ |
| `RUVLTRA_SONA_STATE_DIR` | `./.ruvltra-state/sona` | SONA Áä∂ÊÖã„Éá„Ç£„É¨„ÇØ„Éà„É™ |
| `RUVLTRA_SONA_PERSIST_INTERVAL` | `10` | Ê∞∏Á∂öÂåñÈñìÈöî („Ç§„É≥„Çø„É©„ÇØ„Ç∑„Éß„É≥Êï∞) |
| `RUVLTRA_HTTP_ENDPOINT` | - | HTTP Êé®Ë´ñ„Ç®„É≥„Éâ„Éù„Ç§„É≥„Éà |
| `RUVLTRA_HTTP_API_KEY` | - | HTTP API „Ç≠„Éº |
| `RUVLTRA_HTTP_MODEL` | `ruvltra-claude-code` | HTTP „É¢„Éá„É´Âêç |
| `RUVLTRA_HTTP_FORMAT` | `auto` | `openai` / `llama` |
| `RUVLTRA_HTTP_TIMEOUT_MS` | `15000` | HTTP „Çø„Ç§„É†„Ç¢„Ç¶„Éà |
| `RUVLTRA_HTTP_MAX_RETRIES` | `2` | HTTP „É™„Éà„É©„Ç§ÂõûÊï∞ |
| `RUVLTRA_HTTP_RETRY_BASE_MS` | `250` | „É™„Éà„É©„Ç§ÈñìÈöî„Éô„Éº„Çπ |
| `RUVLTRA_HTTP_CIRCUIT_FAILURE_THRESHOLD` | `5` | „Çµ„Éº„Ç≠„ÉÉ„ÉàÈñãÊîæÈñæÂÄ§ |
| `RUVLTRA_HTTP_CIRCUIT_COOLDOWN_MS` | `30000` | „Çµ„Éº„Ç≠„ÉÉ„Éà„ÇØ„Éº„É´„ÉÄ„Ç¶„É≥ |
| `RUVLTRA_MODEL_PATH` | Ëá™ÂãïÊé¢Á¥¢ | „É≠„Éº„Ç´„É´ GGUF „É¢„Éá„É´„Éë„Çπ |
| `RUVLTRA_RUVLLM_MODEL` | `ruvltra-claude-code` | RuvLLM Ëá™Âãï„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„É¢„Éá„É´ ID |
| `RUVLTRA_CONTEXT_LENGTH` | `4096` | „Ç≥„É≥„ÉÜ„Ç≠„Çπ„ÉàÈï∑ |
| `RUVLTRA_GPU_LAYERS` | `-1` | llama.cpp GPU „É¨„Ç§„É§„ÉºÊï∞ |
| `RUVLTRA_THREADS` | `0` | llama.cpp „Çπ„É¨„ÉÉ„ÉâÊï∞ (0=Ëá™Âãï) |
| `RUVLTRA_MAX_TOKENS` | `512` | ÊúÄÂ§ßÁîüÊàê„Éà„Éº„ÇØ„É≥Êï∞ |
| `RUVLTRA_TEMPERATURE` | `0.2` | ÁîüÊàêÊ∏©Â∫¶ |
| `RUVLTRA_MOCK_LATENCY_MS` | `120` | „É¢„ÉÉ„ÇØ„Éê„ÉÉ„ÇØ„Ç®„É≥„Éâ„ÅÆ„É¨„Ç§„ÉÜ„É≥„Ç∑ |
| `RUVLTRA_LOG_LEVEL` | `info` | `debug` / `info` / `warn` / `error` |
| `RUVLTRA_CONFIG` | - | JSON Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„Éë„Çπ |
| `LLAMA_CPP_PATH` | - | llama.cpp „Éë„Çπ„Éí„É≥„Éà |

---

## English (Current Version)


## Architecture

```
  Claude Code / Gemini CLI / Codex (Command Tower)
                   |
             stdio JSON-RPC
                   v
  +-------------------------------------------+
  | MCP Server Core                           |
  |  - ListTools / CallTool                   |
  |  - outputSchema + structuredContent       |
  |                                           |
  | Tool Handlers (13 tools)                  |
  |  - code_* / parallel_generate / swarm_*   |
  |                                           |
  | Worker Pool (auto-scale 2..8)             |
  |  - queue backpressure                     |
  |  - per-task timeout + cancellation        |
  |  - worker-local SONA                      |
  |                                           |
  | Inference Engine (4-stage fallback)       |
  |  HTTP -> llama.cpp -> RuvLLM -> Mock      |
  |  + HTTP retry/timeout/circuit breaker     |
  +-------------------------------------------+
```

---

## Key Features

- 13 MCP tools (`code_*`, `parallel_generate`, `swarm_review`, management)
- WorkerPool auto-scaling (`min..max`) with queue backpressure
- Per-task timeout and cancellation (`AbortController` based)
- 4-stage inference fallback with automatic recovery to higher-priority backends
- HTTP robustness: timeout, retry, circuit breaker (`open/half_open/closed`)
- SONA self-improvement per worker with disk persistence and reload
- MCP `outputSchema` + `structuredContent` support for stable machine parsing

---

## Quick Start

```bash
npm install
npm run build
npm test
```

Run server:

```bash
node dist/index.js
```

Mock backend works out of the box.  
To use real inference, set at least one backend:

- `RUVLTRA_HTTP_ENDPOINT` (OpenAI-compatible or llama.cpp HTTP)
- or `RUVLTRA_MODEL_PATH` (GGUF for `node-llama-cpp`)
- or install/use `@ruvector/ruvllm`

---

## MCP Client Config Example (Claude Code)

`~/.claude/claude_desktop_config.json`

```json
{
  "mcpServers": {
    "ruvltra": {
      "command": "node",
      "args": ["/path/to/ruvltra-mcp-server/dist/index.js"],
      "env": {
        "RUVLTRA_MIN_WORKERS": "2",
        "RUVLTRA_MAX_WORKERS": "4",
        "RUVLTRA_TASK_TIMEOUT_MS": "60000",
        "RUVLTRA_QUEUE_MAX_LENGTH": "256",
        "RUVLTRA_LOG_LEVEL": "info"
      }
    }
  }
}
```

---

## MCP Tools (13)

### Code tools

- `ruvltra_code_generate`
- `ruvltra_code_review`
- `ruvltra_code_refactor`
- `ruvltra_code_explain`
- `ruvltra_code_test`
- `ruvltra_code_fix`
- `ruvltra_code_complete`
- `ruvltra_code_translate`

### Parallel / swarm

- `ruvltra_parallel_generate`
- `ruvltra_swarm_review`

### Management

- `ruvltra_status`
- `ruvltra_sona_stats`
- `ruvltra_scale_workers`

All tools now define `outputSchema` and return `structuredContent` (plus `content.text` for compatibility).

---

## Tool I/O Contract Notes

- Optional `timeoutMs` is accepted by all generation/review style tools.
- Management tools return structured status/stats objects.
- `ruvltra_status` includes queue metrics and backend/circuit state.

Example `structuredContent` (`ruvltra_code_generate`):

```json
{
  "output": "...",
  "workerId": "worker-2",
  "backend": "http",
  "model": "ruvltra-claude-code",
  "latencyMs": 184,
  "taskId": "task-173..."
}
```

---

## Reliability and Operations

### Queue and backpressure

- `RUVLTRA_QUEUE_MAX_LENGTH` overrun is rejected with a queue overflow error.
- Status tracks: `rejectedTasks`, `queueLength`, `inFlight`.

### Timeout and cancellation

- Per-task timeout via `RUVLTRA_TASK_TIMEOUT_MS` or per-tool `timeoutMs`.
- Timeout triggers cancellation and immediate task failure.

### HTTP resilience

- `RUVLTRA_HTTP_TIMEOUT_MS`
- `RUVLTRA_HTTP_MAX_RETRIES`
- `RUVLTRA_HTTP_RETRY_BASE_MS`
- `RUVLTRA_HTTP_CIRCUIT_FAILURE_THRESHOLD`
- `RUVLTRA_HTTP_CIRCUIT_COOLDOWN_MS`

Circuit opens after consecutive failures, then probes again after cooldown.

### SONA persistence

- `RUVLTRA_SONA_STATE_DIR` (default: `./.ruvltra-state/sona`)
- `RUVLTRA_SONA_PERSIST_INTERVAL` (interactions per flush)

---

## Environment Variables

| Variable | Default | Description |
|---|---:|---|
| `RUVLTRA_MIN_WORKERS` | `2` | Minimum worker count |
| `RUVLTRA_MAX_WORKERS` | `8` | Maximum worker count |
| `RUVLTRA_INITIAL_WORKERS` | `2` | Initial worker count |
| `RUVLTRA_QUEUE_MAX_LENGTH` | `256` | Max queued tasks before backpressure |
| `RUVLTRA_TASK_TIMEOUT_MS` | `60000` | Default per-task timeout |
| `RUVLTRA_SONA_ENABLED` | `true` | Enable SONA |
| `RUVLTRA_SONA_STATE_DIR` | `./.ruvltra-state/sona` | SONA state directory |
| `RUVLTRA_SONA_PERSIST_INTERVAL` | `10` | Persist every N interactions |
| `RUVLTRA_HTTP_ENDPOINT` | - | HTTP inference endpoint |
| `RUVLTRA_HTTP_API_KEY` | - | HTTP API key |
| `RUVLTRA_HTTP_MODEL` | `ruvltra-claude-code` | HTTP model name |
| `RUVLTRA_HTTP_FORMAT` | `auto` | `openai` or `llama` |
| `RUVLTRA_HTTP_TIMEOUT_MS` | `15000` | HTTP timeout |
| `RUVLTRA_HTTP_MAX_RETRIES` | `2` | HTTP retry count |
| `RUVLTRA_HTTP_RETRY_BASE_MS` | `250` | Retry backoff base |
| `RUVLTRA_HTTP_CIRCUIT_FAILURE_THRESHOLD` | `5` | Failures before opening circuit |
| `RUVLTRA_HTTP_CIRCUIT_COOLDOWN_MS` | `30000` | Circuit cooldown |
| `RUVLTRA_MODEL_PATH` | auto-search | Local GGUF model path |
| `RUVLTRA_CONTEXT_LENGTH` | `4096` | Context tokens |
| `RUVLTRA_GPU_LAYERS` | `-1` | llama.cpp GPU layers |
| `RUVLTRA_THREADS` | `0` | llama.cpp thread count (0=auto) |
| `RUVLTRA_MAX_TOKENS` | `512` | Default max generation tokens |
| `RUVLTRA_TEMPERATURE` | `0.2` | Default temperature |
| `RUVLTRA_MOCK_LATENCY_MS` | `120` | Mock backend latency |
| `RUVLTRA_LOG_LEVEL` | `info` | `debug/info/warn/error` |
| `RUVLTRA_CONFIG` | - | Optional JSON config file |
| `LLAMA_CPP_PATH` | - | Optional llama.cpp path hint |

---

## Testing

```bash
# full suite
npm test

# targeted
npm run test:smoke
npm run test:pool
npm run test:resilience
npm run test:sona
npm run test:parallel

# build
npm run build
```

Current tests cover:

- MCP smoke and structured output checks
- queue backpressure and timeout/cancel behavior
- HTTP retry and circuit-breaker recovery path
- SONA persistence and reload

CI is configured in [ci.yml](.github/workflows/ci.yml).

---

## Publishing

### 1. Local preflight

```bash
npm ci
npm test
npm run build
npm pack
```

`prepublishOnly` already enforces `npm test && npm run build`.

### 2. Manual publish

```bash
npm publish --access public --provenance
```

### 3. CI publish (recommended)

- Tag release: `vX.Y.Z`
- Push tag to GitHub
- [publish.yml](.github/workflows/publish.yml) runs test/build/publish
- Required secret: `NPM_TOKEN`

### 4. Install and run

```bash
npx -y ruvltra-mcp-server
```

or in MCP config:

```json
{
  "command": "npx",
  "args": ["-y", "ruvltra-mcp-server"]
}
```

---

## Project Structure

```
src/
  index.ts                        # „Ç®„É≥„Éà„É™„Éº„Éù„Ç§„É≥„Éà
  types.ts                        # ÂÖ±ÈÄöÂûãÂÆöÁæ©
  core/
    mcp-server.ts                 # MCP „Çµ„Éº„Éê„Éº„Ç≥„Ç¢
  tools/
    definitions.ts                # 13„ÉÑ„Éº„É´„ÅÆÂÆöÁæ©„Å® outputSchema
    handlers.ts                   # „ÉÑ„Éº„É´„Éè„É≥„Éâ„É©„ÉºÂÆüË£Ö
  workers/
    worker-pool.ts                # „ÉØ„Éº„Ç´„Éº„Éó„Éº„É´ („Çπ„Ç±„Éº„É™„É≥„Ç∞„Éª„Ç≠„É•„Éº)
  ruvllm/
    inference-engine.ts           # 4ÊÆµÈöé„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÊé®Ë´ñ„Ç®„É≥„Ç∏„É≥
    sona-engine.ts                # SONA Ëá™Â∑±ÊîπÂñÑ„Ç®„É≥„Ç∏„É≥
  config/
    defaults.ts                   # Ë®≠ÂÆö„ÉªÁí∞Â¢ÉÂ§âÊï∞„Éë„Éº„Çµ„Éº
  utils/
    logger.ts                     # „É≠„Ç¨„Éº
tests/
  test-mcp.ts                     # MCP „Çπ„É¢„Éº„ÇØ„ÉÜ„Çπ„Éà
  test-parallel.ts                # ‰∏¶ÂàóÁîüÊàê„ÉÜ„Çπ„Éà
  test-timeout-backpressure.ts    # „Çø„Ç§„É†„Ç¢„Ç¶„Éà„Éª„Éê„ÉÉ„ÇØ„Éó„É¨„ÉÉ„Ç∑„É£„Éº„ÉÜ„Çπ„Éà
  test-http-resilience.ts         # HTTP „É™„Éà„É©„Ç§„Éª„Çµ„Éº„Ç≠„ÉÉ„Éà„Éñ„É¨„Éº„Ç´„Éº„ÉÜ„Çπ„Éà
  test-sona-persist.ts            # SONA Ê∞∏Á∂öÂåñ„ÉÜ„Çπ„Éà
  test-llama.ts                   # llama.cpp „Éê„ÉÉ„ÇØ„Ç®„É≥„Éâ„ÉÜ„Çπ„Éà
  test-ruvllm.ts                  # RuvLLM „Éê„ÉÉ„ÇØ„Ç®„É≥„Éâ„ÉÜ„Çπ„Éà
  test-ruvllm[2-5].ts             # RuvLLM ËøΩÂä†„ÉÜ„Çπ„Éà„Éê„É™„Ç®„Éº„Ç∑„Éß„É≥
```
